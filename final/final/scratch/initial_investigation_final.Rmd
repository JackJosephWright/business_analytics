---
title: "final_initial"
author: "Jack Wright"
date: "10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(here)
```

```{r}
file<-here('kaggle_files','train.csv')
df_raw<-read.csv(file)
```

## Tidying 

## Columns overview

```{r}
colnames(df_raw)
```

### ChannelGrouping

```{r}
df_raw$channelGrouping<-as.factor(df_raw$channelGrouping)

```



```{r}
levels(as.factor(df_raw$channelGrouping))

```


```{r}

```


## TOTALS column to Dataframe



```{r}
#function for turning python dictionary to a R dataframe

dict_df <-function(d){
  
}

dict_to_df = function(dict) {
  
  require(plyr)
  df = data.frame()
  df_temp = list()
  store = list()
  
  for (i in 1:length(dict)) {

    # Split up the dictionary entry
    split = unlist(strsplit(dict[i], '\",'))
    split = gsub('\\{|\\}', '', split)
    #split = gsub('\\}', '', split)
    values = unlist(strsplit(split, ':'))

    # Parse out what will be the df headers
    headers = values[seq(1, length(values), 2)]       
    headers = gsub('\"', '', headers) # Remove quotes
    headers = gsub(' ', '', headers)  # and whitespace

    # Parse out what will be the df values
    row_values = values[seq(0, length(values), 2)]
    row_values = gsub('\"', '', row_values) # Remove quotes
    row_values = gsub(' ', '', row_values)  # and whitespace

    # Construct a dataframe with 1 row
    out = data.frame(t(row_values))
    colnames(out) = headers

    store[i] = list(out)

    #if (i %% 1000 == 0) { print(round(i / length(dict), 2)) }

  }

    # rbind all the dataframes together into one dataframe 
    list_length = length(store)
    
    # If the dictionary is sufficiently large rbind will be slow
    # as all hell, so break the rbinding into multiple steps
    if (list_length >= 3000) {

      no_splits = round(list_length / 500)
      chunks = split(store, 1:no_splits)

      for (j in 1:no_splits) {

        df_temp[j] = list(rbind.fill(chunks[[j]]))
        
      }
      df = rbind.fill(df_temp)
      return(df)
    }

    else {

      df = rbind.fill(store)
      return(df)
    }

}

```

make dataframe for `totals` column

```{r}
df_total<-dict_to_df(df_raw$totals)
```

make dataframe for other columns

```{r}
library(jsonlite)
df_device <- paste("[", paste(df_raw$device, collapse = ","), "]") %>% fromJSON(flatten = T)

df_geoNetwork <- paste("[", paste(df_raw$geoNetwork, collapse = ","), "]") %>% fromJSON(flatten = T)
df_totals <- paste("[", paste(df_raw$totals, collapse = ","), "]") %>% fromJSON(flatten = T)
df_trafficSource <- paste("[", paste(df_raw$trafficSource, collapse = ","), "]") %>% fromJSON(flatten = T)
```



```{r}
df <- df_raw %>%
    cbind(df_device, df_geoNetwork, df_totals, df_trafficSource) %>%
    select(-device, -geoNetwork, -totals, -trafficSource)

factorVars <- c("channelGrouping", "browser", "operatingSystem", "deviceCategory", "country")
df[, factorVars] <- lapply(df[, factorVars], as.factor)
df$transactionRevenue <- as.numeric(df$transactionRevenue)

numVars <- c("visits", "hits", "bounces", "pageviews", "newVisits")
df[, numVars] <- lapply(df[, numVars], as.integer)

df$visitStartTime <- as.POSIXct(df$visitStartTime, tz="UTC", origin='1970-01-01')
library(readr)
write_csv(df, file='train_clean_jack.csv')
```


```{r}
library(lubridate)
df <- df %>% mutate(date=ymd(date))
nan_count <- sum(!is.na(df$transactionRevenue))
nan_pct <- nan_count / nrow(df) * 100
total_rev <- sum(df$transactionRevenue, na.rm=T)
```



