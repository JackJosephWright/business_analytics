#assess covariance
df%>%
# select(!index)%>%
correlate()%>%
filter(coef_corr > .4 | coef_corr < -.4)
df%>%plot_correlate()
#impute numerical vars using dlookr, methods have been preselected based on initial plots.
#car_age
car_age<-imputate_na(df, car_age, target_flag, method = "mice", seed = 999)
plot(car_age)+theme_minimal()+theme(legend.position = "top")
summary(car_age)
#home_val
home_val<-imputate_na(df, home_val, target_flag, method = "rpart")
plot(home_val)+theme_minimal()+theme(legend.position = "top")
summary(home_val)
#yoj
yoj<- imputate_na(df, yoj, target_flag, method = "rpart")
plot(yoj)+theme_minimal()+theme(legend.position = "top")
summary(yoj)
# income
income<-imputate_na(df, income, target_flag, method = "rpart")
plot(income)+theme_minimal()+theme(legend.position = "top")
summary(income)
#age
age<-imputate_na(df, age, method = "rpart")
plot(age)+theme_minimal()+theme(legend.position = "top")
summary(age)
temp<-cbind(car_age, home_val, yoj, income, age)
temp%<>%as.data.frame(temp)
df%<>%select(!c(car_age, home_val, yoj, income, age))%>%
cbind(temp)
df%<>%mutate_if(is.numeric, round)
#write.csv(df, 'C://Users//seanc//Documents//Data_Science//CUNY//621_BusinessAnalytics//insurance_model//df_clean.csv', row.names=FALSE)
job<-imputate_na(df, job, method = "mice", seed = 999)
plot(job)+theme_minimal()+theme(legend.position = "top")
# combine into new dfb
df<-df%>%select(!job)
df<-cbind(df,job)
df$job<-factor(df$job)
#write.csv(df, 'C://Users//seanc//Documents//Data_Science//CUNY//621_BusinessAnalytics//insurance_model//df_clean_imputed.csv', row.names=FALSE)
diagnose_outlier(df) %>% flextable()
df %>%
select(find_outliers(df, index = FALSE)) %>%
plot_outlier()
df %>%
target_by(target_flag) %>%
relate(parent1) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(mstatus) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(sex) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(education) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(job) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(car_use) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(car_type) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(red_car) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(revoked) %>%
plot()
df %>%
target_by(target_flag) %>%
relate(urbanicity) %>%
plot()
num_box<-select_if(df, is.numeric)
num_box<-cbind(df$target_flag, num_box)%>%
rename(target_flag = 'df$target_flag')
response = names(num_box)[1] #target_flag
response = purrr::set_names(response)
explain <- names(num_box)[3:16] #explanatory variables
explain = purrr::set_names(explain)
box_fun = function(x) {
ggplot(num_box, aes_string(x = x, y = 'target_flag') ) +
geom_boxplot(aes(fill = target_flag, alpha = 0.4), outlier.color =
'red', show.legend = FALSE)+
scale_fill_viridis(discrete = TRUE, option = "E")+
coord_flip()+
theme_classic()
}
b_plots<-map(explain, ~box_fun(.x)) #creates a list of plots
ggarrange(plotlist=b_plots, height = .5, ncol = 3)
df%<>%
select(!c(target_amt))
# change kidsdrive to categorical
df%<>%
mutate(kidsdriv = case_when(kidsdriv == 0 ~ 'N'
,TRUE  ~ 'Y'))
# change job into blue collar and professional levels
df%<>%
mutate(job = case_when(job == 'Blue Collar' ~ 'Blue Collar',
job != 'Blue Collar' ~ 'Professional',
TRUE ~ as.character(NA)))
df%<>%mutate(job = na_if(job, "NA"))
#change chars to factors and level education
df %<>%mutate_if(is_character, ~(factor(.)))%>%select(!index)
df$education<-factor(df$education, levels=c("High School", "Bachelors", "Masters", "PhD"))
#build model
base_df<-df
model1 <- glm(target_flag ~ .,family='binomial', base_df)
model1_aki<-step(model1, trace=0) # use Akiaike step, trace 0 prevents intermediate printing, rename model to preserve base
summary(model1_aki)
#look at fit metrics - create parallel df for this purpose
model1_df<-base_df%>%
select(!c(sex, age, car_age, red_car)) # nonsignificant in model1
model1_df$predicted<-predict(model1_aki, type='response')
model1_df%<>%
mutate(predicted_obs = case_when(
predicted >= 0.5 ~ 1,
predicted < 0.5 ~ 0))
model1_df$predicted_obs<-as.factor(model1_df$predicted_obs)
model1_df$target_flag<-as.factor(model1_df$target_flag)
#create confusion matrix
(model1_cm<-confusionMatrix(data = model1_df$predicted_obs, reference = model1_df$target_flag))
# related model results - drawing code from HW3
(model1_metrics <- tibble(model = "Base Model: base variables",
predictors = length(coef(model1_aki))-1,
precision = model1_cm$byClass[5],
auc = auc(roc(response = as.numeric(model1_df$target_flag),
predictor = as.numeric(model1_df$predicted)))[1],  #note: using predicted (probs) vs predicted_obs (0,1)
AIC = model1_aki$aic, BIC = BIC(model1_aki)))
#roc curve with AUC
par(pty='s')
proc<- roc(response=model1_df$target_flag, predictor=model1_df$predicted, plot=TRUE, legacy.axes=TRUE, auc.polygon=TRUE, col='blue', main = 'Model 1 ROC Curve', max.auc.polygon=TRUE, print.auc=TRUE)
# evaluate using deviance and quasibinomial comparison
deviance(model1_aki)/df.residual(model1_aki) # if considerably greater than one we should be concerned
# dble check with two model fit
quasi_model <-  glm(target_flag ~ .,family='quasibinomial', base_df) # note: using base_df
pchisq(summary(quasi_model)$dispersion * model1_aki$df.residual,
model1_aki$df.residual, lower = F)
#incorporate logit into model1_df
model1_df%<>%
mutate(logit = log(predicted/(1-predicted)))
# check linearity btwn numerical predictors and logit
with(model1_df, scatter.smooth(travtime, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(tif, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(mvr_pts, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(home_val, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(yoj, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(income, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(homekids, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(oldclaim, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(clm_freq, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(model1_df, scatter.smooth(bluebook, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
# Extract model results
model1_aki$data <- augment(model1_aki) %>%
mutate(index = 1:n())
#top 10 largest values
model1_aki$data %>% top_n(10, .cooksd)
plot(model1_aki, which = 4, id.n = 3)  # keep an eye on obs > 4/n
#plot std residuals
ggplot(model1_aki$data, aes(index, .std.resid)) +
geom_point(aes(color = target_flag), alpha = .5) +
theme_bw()
#Filter potential influential data points with abs(.std.res) > 3
model1_aki$data %>%
filter(abs(.std.resid) > 3)
car::vif(model1_aki)
res_chk<-model1_df%>%mutate('residuals' = residuals(model1_aki), linpred = predict(model1_aki))
bins<- group_by(res_chk, cut(linpred, breaks=unique(quantile(linpred, (1:100)/101))))
diag<-summarize(bins, residuals=mean(residuals), linpred = mean(linpred))
plot(residuals~linpred, diag, xlab = "linear predictor")
marginals<-mmps(model1_aki,main=NULL)
#create df to contain log transformed vars from model
model2_df<-model1_df%>%
select(!c(predicted, predicted_obs))%>%
mutate(sqrt_travtime = sqrt(travtime))%>%
mutate(sqrt_mvr_pts = sqrt(mvr_pts))%>%
mutate(sqrt_yoj = sqrt(yoj))%>%
mutate(sqrt_clm_freq = sqrt(clm_freq))%>%
mutate(log_bluebook= log(bluebook))%>%
mutate(sqrt_income=sqrt(income))
model2_df%<>%
select(!c(travtime, mvr_pts, yoj, clm_freq, bluebook, income))
#build model with transformed vars
model2 <- glm(target_flag~kidsdriv+homekids+parent1+mstatus+education+car_use+tif+car_type+oldclaim+revoked+urbanicity+home_val+job+sqrt_travtime+sqrt_mvr_pts+sqrt_yoj+sqrt_clm_freq+log_bluebook+sqrt_income,family='binomial',model2_df)
model2_aki<-step(model2, trace=0)
summary(model2_aki)
#additional metrics
model2_df$predicted<-predict(model2_aki, type='response')
model2_df%<>%
mutate(predicted_obs = case_when(
predicted >= 0.5 ~ 1,
predicted < 0.5 ~ 0))
model2_df$predicted_obs<-as.factor(model2_df$predicted_obs)
model2_df$target_flag<-as.factor(model2_df$target_flag)
#confusion matrix
model2_cm<-confusionMatrix(data = model2_df$predicted_obs, reference = model2_df$target_flag)
# interaction results
model2_mtrics <- tibble(model = "transformation Model: base variables",
predictors = length(coef(model2_aki))-1,
precision = model2_cm$byClass[5],
auc = auc(roc(response = as.numeric(model2_df$target_flag),
predictor = as.numeric(model2_df$predicted)))[1],
AIC = model2_aki$aic, BIC = BIC(model2_aki))
#roc curve with AUC
par(pty='s')
proc<- roc(response=model2_df$target_flag, predictor=model2_df$predicted, plot=TRUE, legacy.axes=TRUE, auc.polygon=TRUE, col='blue', main = 'PROC ROC Curve', max.auc.polygon=TRUE, print.auc=TRUE)
#review marginal plots
model2_marg<-mmps(model2_aki,main=NULL)
#create df to contain log transformed vars from model
model2b_df<-model1_df%>%
select(!c(predicted, predicted_obs))%>%
mutate(sqrt_yoj = sqrt(yoj))%>%
mutate(log_bluebook= log(bluebook))%>%
mutate(sqrt_income=sqrt(income))
model2b_df%<>%
select(!c( yoj, bluebook, income))
#build model with transformed vars
model2b <- glm(target_flag~kidsdriv+homekids+parent1+mstatus+education+car_use+tif+car_type+oldclaim+revoked+urbanicity+home_val+job+travtime+I(travtime^2)+mvr_pts+I(mvr_pts^2)+I(mvr_pts^3)+sqrt_yoj+clm_freq+I(clm_freq^2)+I(clm_freq^3)+log_bluebook+sqrt_income,family='binomial',model2b_df)
model2b_aki<-step(model2b, trace=0)
summary(model2b_aki)
#additional metrics
model2b_df$predicted<-predict(model2b_aki, type='response')
model2b_df%<>%
mutate(predicted_obs = case_when(
predicted >= 0.5 ~ 1,
predicted < 0.5 ~ 0))
model2b_df$predicted_obs<-as.factor(model2b_df$predicted_obs)
model2b_df$target_flag<-as.factor(model2b_df$target_flag)
#confusion matrix
(model2b_cm<-confusionMatrix(data = model2b_df$predicted_obs, reference = model2b_df$target_flag))
# interaction results
(model2b_metrics <- tibble(model = "transformation Model 2b: base variables",
predictors = length(coef(model2b_aki))-1,
precision = model2b_cm$byClass[5],
auc = auc(roc(response = as.numeric(model2b_df$target_flag),
predictor = as.numeric(model2b_df$predicted)))[1],
AIC = model2b_aki$aic, BIC = BIC(model2b_aki)))
#roc curve with AUC
par(pty='s')
proc<- roc(response=model2b_df$target_flag, predictor=model2b_df$predicted, plot=TRUE, legacy.axes=TRUE, auc.polygon=TRUE, col='blue', main = 'PROC ROC Curve', max.auc.polygon=TRUE, print.auc=TRUE)
#review marginal plots
model2b_marg<-mmps(model2b_aki,main=NULL)
res2b_chk<-model2b_df%>%mutate('residuals' = residuals(model2b_aki), linpred = predict(model2b_aki))
bins<- group_by(res2b_chk, cut(linpred, breaks=unique(quantile(linpred, (1:100)/101))))
diag<-summarize(bins, residuals=mean(residuals), linpred = mean(linpred))
plot(residuals~linpred, diag, xlab = "linear predictor")
hist(res2b_chk$residuals)
library(ggResidpanel)
resid_panel(model2b_aki)
res2b_chk$linpred
hist(res2b_chk$linpred)
res2b_chk%>%mutate(p_binary=case_when(linpred>.5~1,
TRUE~0))
res2b_chk<-res2b_chk%>%mutate(p_binary=case_when(linpred>.5~1,
TRUE~0))
hist(res2b_chk$p_binary)
raw <- read_csv(here('data','insurance_training_data.csv'))
raw <- read_csv(here('data','insurance_training_data.csv'))
raw%<>%clean_names
gc()
library(tidyverse)
library(janitor)
library(magrittr)
library(flextable)
library(dlookr) # eda
library(ggpubr) # creates a wrapper for plotting a list
library(viridis)
library(broom) # creates a tidy data frame from statistical test results
library(car) # VIF
library(lmtest) #partial likelihood test for model fit comparisons
library(caret) # conf matrix
library(car) # marginal model plot
library(pROC) #roc curve
raw <- read_csv(here('data','insurance_training_data.csv'))
raw%<>%clean_names
View(raw)
raw <- read_csv(here('data','insurance_training_data.csv'))
View(raw)
?clean_names
View(raw)
raw%<>%remove_empty(c("rows", "cols"))
get_dupes(raw)
str(raw)
df<-raw%>%
mutate_if(is_character, str_replace_all, '\\$|,|z_|<', '')%>%
mutate_at(c(8,10,17,21), as.numeric)%>%
mutate_at(c(2), as.factor)
df%<>%mutate_if(is.numeric, round)
View(df)
id_distinct <- df%>%
select(where(is_character))%>%
map(~str_c(unique(.x),collapse = ",")) %>%
bind_rows() %>%
gather(key = col_name, value = col_unique)
View(id_distinct)
df%<>%
mutate_if(is_character, str_replace_all, "No|no",'N')%>%
mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')
df %<>%mutate_if(is_character, ~(factor(.)))
df$education<-factor(df$education, levels=c("High School", "Bachelors", "Masters", "PhD"))
df%<>%
mutate_if(is_character, str_replace_all, "No|no",'N')%>%
mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')
df %<>%mutate_if(is_character, ~(factor(.)))
df$education<-factor(df$education, levels=c("High School", "Bachelors", "Masters", "PhD"))
View(df)
View(raw)
raw <- read_csv(here('data','insurance_training_data.csv'))
# initial clean of col names
raw%<>%clean_names
# remove any empty rows and cols
raw%<>%remove_empty(c("rows", "cols"))
# assess presence of duplicates
get_dupes(raw)
# basic characterization
str(raw)
#clean extraneous symbols from char col values and convert to numeric as appropriate
df<-raw%>%
mutate_if(is_character, str_replace_all, '\\$|,|z_|<', '')%>%
mutate_at(c(8,10,17,21), as.numeric)%>%
mutate_at(c(2), as.factor)
# round numeric columns
df%<>%mutate_if(is.numeric, round)
# identify unique values in our character cols
id_distinct <- df%>%
select(where(is_character))%>%
map(~str_c(unique(.x),collapse = ",")) %>%
bind_rows() %>%
gather(key = col_name, value = col_unique)
# Update col values for clarity and brevity
df%<>%
mutate_if(is_character, str_replace_all, "No|no",'N')%>%
mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')
# convert character cols to factor and set level for education col
df %<>%mutate_if(is_character, ~(factor(.)))
df$education<-factor(df$education, levels=c("High School", "Bachelors", "Masters", "PhD"))
str(df)
?diagnose
df%>%diagnose()
df%>%
dlookr::diagnose()%>%
select(-unique_count, -unique_rate)
df%>%
dlookr::diagnose()%>%
select(-unique_count, -unique_rate)%>%
filter(missing_count>0)%>%
arrange(desc(missing_count))%>%
flextable()
?plot_na_pareto
df%>%dlookr::plot_na_pareto(only_na = TRUE) # only plots vars with missing
df%>%dlookr::plot_na_intersect(only_na = TRUE)
?find_skewness
df%>%dlookr::find_skewness(index=FALSE, thres=TRUE) #this is good
df%>%dloork::find_outliers(index=FALSE, rate=TRUE) # this is good
df%>%dlookr::find_outliers(index=FALSE, rate=TRUE) # this is good
df%>%normality()
df%>%plot_normality()
?plot_normality
df%>%group_by(target_flagt)%>%dlookr::plot_normality()
df%>%group_by(target_flag)%>%dlookr::plot_normality()
df%>%
diagnose_category()%>%
flextable(theme_fun = theme_booktabs())
df$car_age[df$car_age < 0] <- NA
?correlate
#assess covariance
df%>%
# select(!index)%>%
dlookr::correlate()%>%
filter(coef_corr > .4 | coef_corr < -.4)
df%>%plot_correlate()
?plot_correlate
?impute_na
?imputate_na
car_age<-dlookr::imputate_na(df, car_age, target_flag, method = "mice", seed = 999)
car_age<-dlookr::imputate_na(df, car_age, target_flag, method = "mice", seed = 999)
plot(car_age)+theme_minimal()+theme(legend.position = "top")
summary(car_age)
#impute numerical vars using dlookr, methods have been preselected based on initial plots.
#car_age
car_age<-dlookr::imputate_na(df, car_age, target_flag, method = "mice", seed = 999)
plot(car_age)+theme_minimal()+theme(legend.position = "top")
summary(car_age)
#home_val
home_val<-imputate_na(df, home_val, target_flag, method = "rpart")
plot(home_val)+theme_minimal()+theme(legend.position = "top")
summary(home_val)
#yoj
yoj<- imputate_na(df, yoj, target_flag, method = "rpart")
plot(yoj)+theme_minimal()+theme(legend.position = "top")
summary(yoj)
# income
income<-imputate_na(df, income, target_flag, method = "rpart")
plot(income)+theme_minimal()+theme(legend.position = "top")
summary(income)
#age
age<-imputate_na(df, age, method = "rpart")
plot(age)+theme_minimal()+theme(legend.position = "top")
summary(age)
temp<-cbind(car_age, home_val, yoj, income, age)
temp%<>%as.data.frame(temp)
df%<>%select(!c(car_age, home_val, yoj, income, age))%>%
cbind(temp)
df%<>%mutate_if(is.numeric, round)
#write.csv(df, 'C://Users//seanc//Documents//Data_Science//CUNY//621_BusinessAnalytics//insurance_model//df_clean.csv', row.names=FALSE)
job<-imputate_na(df, job, method = "mice", seed = 999)
plot(job)+theme_minimal()+theme(legend.position = "top")
# combine into new dfb
df<-df%>%select(!job)
df<-cbind(df,job)
df$job<-factor(df$job)
write.csv(df, 'df_clean_imputed.csv', row.names=FALSE)
?plot_outlier
?relate
?target_by
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
df<-read.csv(here('df_clean_imputed.csv'))
View(df)
gc()
df<-read.csv(here('df_clean_imputed.csv'))
View(df)
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)
View(df)
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-target_flag)%>%reorder(target_amt)
View(df)
?reorder
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-target_flag)%>%reorder(.,target_amt)
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-target_flag)
df<-df%>%reorder(target_amt)
View(df)
df%>%reorder(homekids)
reorder(df,target_amt)
df%>%stats::reorder(homekids)
df<-df%>%reorder(df$target_amt)
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-c(target_flag,index))%>%relocate(target_amt)
View(df)
ggpairs(df)
response_df<-df$target_amt
predictor_df<-df%>%select(-target_amt)
lm_list[['lm.base']]<-lm(target_amt~.,data=df)
lm_list<-list()
lm_list[['lm.base']]<-lm(target_amt~.,data=df)
summary(lm_list[['lm.base']])
resid_panel(lm_list[['lm.base']])
library(dlookr)
df%>%dlookr::plot_correlate()
raw<-read.csv(here('data','insurance_training_data.csv'))
#load only target_flag==1
#df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-c(target_flag,index))%>%relocate(target_amt)
#load clean data
raw<-read.csv(here('data','insurance_training_data.csv'))
raw%<>%clean_names
# remove any empty rows and cols
raw%<>%remove_empty(c("rows", "cols"))
# assess presence of duplicates
get_dupes(raw)
# basic characterization
str(raw)
#clean extraneous symbols from char col values and convert to numeric as appropriate
df<-raw%>%
mutate_if(is_character, str_replace_all, '\\$|,|z_|<', '')%>%
mutate_at(c(8,10,17,21), as.numeric)%>%
mutate_at(c(2), as.factor)
# round numeric columns
df%<>%mutate_if(is.numeric, round)
# identify unique values in our character cols
id_distinct <- df%>%
select(where(is_character))%>%
map(~str_c(unique(.x),collapse = ",")) %>%
bind_rows() %>%
gather(key = col_name, value = col_unique)
# Update col values for clarity and brevity
df%<>%
mutate_if(is_character, str_replace_all, "No|no",'N')%>%
mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')
# convert character cols to factor and set level for education col
df %<>%mutate_if(is_character, ~(factor(.)))
df$education<-factor(df$education, levels=c("High School", "Bachelors", "Masters", "PhD"))
response_df<-df$target_amt
predictor_df<-df%>%select(-target_amt)
df%>%dlookr::plot_correlate()
hist(df$target_amt)
#load only target_flag==1
df<-read.csv(here('df_clean_imputed.csv'))%>%filter(target_flag==1)%>%select(-c(target_flag,index))%>%relocate(target_amt)
df%>%dlookr::plot_correlate()
hist(df$target_amt)
ggplot(df, aes(x=target_amt))+geom_hist()
ggplot(df, aes(x=target_amt))+geom_histogram()
lm_list[['lm.base']]<-lm(target_amt~bluebook,data=df)
summary(lm_list[['lm.base']])
resid_panel(lm_list[['lm.base']])
