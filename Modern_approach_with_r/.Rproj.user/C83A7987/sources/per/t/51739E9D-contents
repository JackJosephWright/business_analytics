---
title: "marginal_model_plot"
author: "Jack Wright"
date: "10/21/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Marginal model plot notes

graphical method for deciding if logistic regression model is adequate


kyphosis data. Outcome is 1,0 (presence of kyphosis)

```{r}
library(tidyverse)
library(GGally)
kyp <- read.table(url("http://www.stat.umn.edu/~sandy/courses/5421/data/kyphosis.txt"), header = TRUE)
ggpairs(kyp%>%select(-Outcome))

```

```{r}
ggplot(kyp, aes(x=(Age+Number+Start)^2,y=Outcome))+geom_point()
```

fitting models

```{r}
library(car)
Anova(bigmodel <- glm(Outcome ~ (Age + Number + Start)^2,
data = kyp, family = binomial), type = "II")
```

```{r}
Anova(m <- update(bigmodel, ~. - Age:Start - Number:Start -
Age:Number))

```
```{r}

residualPlots(m, type = "pearson", layout=c(2,2))
```

residuals are hard to use in ungrouped log regression because they are 1-fitte for y=1 or -fitted for y=0

USE MARGINAL PLOTS


## Marginal Model Plots

1.

fix a plotting direction (either 1 predictor or a combo of predictor ) such as the linear predictor estimated by the model


2.

draw the plot with Y on the vertical axis vs plotting direction on the horizontal axis

EX: in a plot vs AGE, it estimates the conditional probability for a fixed age. 

*estimated without reference to the fitted logistic model*

4.

use fitted logistic model to estimate this conditional probabilty and draw it on the same graph


5. 

IF THE TWO LINES ARE SIMILAR THE MODEL IS REPRODUCINT THE DATA IN THAT DIRECTIOn

if they are different SOMETHING IS WRONG

```{r}
mmps(m,span=3/4, layout = c(2,2))
```


```{r}
Anova(m1 <- update(m, ~. + I(Age^2)))
```

```{r}
mmps(m1, span = 3/4)

```


comparing the models

```{r}
library(car)
anova(glm.full,glm.full_2)


```
it isnt giving me the p value of the difference in deviance

so

```{r}
pchisq(6.61,1,lower.tail = FALSE)
```


```{r}
resid_interact(glm.full_2, plots='lev')
```

look at leverage values and standardized deviance residuals

the highest leverage are also the highest price, so we can say this is due to their extreme prices

```{r}
summary(glm.full_2)
```

since price is only marginally significant, remove it

then we use anova to compare the model with it and without it
So the hypothesis test

H 0:
$H_0:\beta_4=0$ (model without price)
$H_A:\beta_4\neq0$ (model WITH price)
```{r}
glm.2<-glm.full_2
glm.3<-update(glm.2,~.-Price)

#compare with anova

anova(glm.3,glm.2)
```
check p value (should be included here)

```{r}
pchisq(1.4,1,lower.tail=FALSE)
```

p-value is high so we DO NOT reject null hypothesis?

NOTE:

this p value is HIGHER than the Wald p-value for the coefficient of price (.091)

*illustration of how wald tests and tests based on the DIFFERENCE IN DEVIANCES can result in different p-values*

Also: we guessed the leverage problems came from price
(which could lead to underestemation of regression coefficient)

the new model is preffered

```{r}
summary(glm.3)
```

model looks good

NOTES:

1.

all of the predictors we would intuit would make the odds of being included in michelin higher are positive
(GOOD)

2.

the coefficient of interaction Decor:Service is negative MODERATING the main effects of decor on service



CHECK VALIDITY WITH MARGINAL MODEL PLOTS

```{r}
mmps(glm.3)
```

