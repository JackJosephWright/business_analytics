---
title: "ch_5_mARR"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(here)

```



Multiple Linear Regression


Polynomial Regression


predictor is a single predictor and its polynomial powers


polynomial regression, can display the results of multiple regression on single 2D graph




## Example

develop a regression equation to model the relationship between Y=salary and x= num years of experiance 


THEN:

find 95% prediction interval for Y when x=10.

```{r}
library(tidyverse)
file<-here('data','profsalary.txt')
dat<-read.table(file, header = TRUE)
```

```{r}
ggplot(dat, aes(x=Experience, y=Salary))+geom_point()
```

consider simple linear regression model

```{r}
summary(lm.model<-lm(Salary~Experience, data=dat))
```
```{r}
library(ggResidpanel)
resid_panel(lm.model, plots = 'all')
```

now with quadratic term

```{r}
(summary(lm.model<-lm(Salary~Experience+I(Experience^2), data=dat)))
confint(lm.model)
```

prediction for 10 years experience

```{r}
predict(lm.model,newdata = data.frame(Experience=10), interval = 'predict' )
```
```{r}
resid_panel(lm.model, plots='all')
```


## Estimation and Inference in Multiple Linear Regression




## Matrix formulation of least squares


matrix vector notation for least squares with multiple predictors

that way you can write linear regression with matrix notation

$$\mathbf{Y}=\mathbf{X}\beta+\mathbf{e}$$



### properties of least squares estimates

consider


F-test is always used first to test for the existence of a linear association between Y and ANY of the p x-variables. 

if F-tests is significant, then a natural question to ask

"for which of the p x-variables is there evidence of a linear association with Y?


**testing whether a specified subset of the predictors have regression coefficients equal to 0**

achieved with F-tests


let RSS(full) be residual sum of squares under the full model. (includes all the predictors)

RSS(reduced) be sum of squares under reduced model (model that only includes predictors thought to be non-zero)


F-statistic is given by

$$F=\frac{RSS(Reduced)-RSS(full)/df_{reduced}-df_{full}}{RSS(full)/df_{full}}$$



## Example Menu pricing in a new Italian restaurant in NYC


```{r}
file<-here('data','nyc.csv')
dat<-read.csv(file)
```


a. 

develop regression model that directly predicts the price of dinner (in dollars) using a subset or all 4 of the potential predictiors

```{r}
summary(lm.model<-lm(Price~., data=dat%>%select(-c(Case, Restaurant,Service))))
```

```{r}
ggpairs(dat%>%select(-c(Case,Restaurant)))
```
```{r}
resid_panel(lm.model, plots = 'all')
```

Note: we say Decor has the largest effect on price since its regression coefficient is largest (it isnt'... maybe because it is more significant) (this might have to do with scale. since east is a binary)




## Analysis of Covariance


model response variable Y based on continuous predictor, x and dummy variable d. 

Suppose the effect of x on Y is linear. Situation is simplest version of what is reffered to as Analysis of Covariance. since its predictors include both quantitative and qualitative variables. 


**coincident regression lines**

simplest model in the given situation is one in which the dummy variable has no effect on Y, that is, 

$$Y=\beta_0+\beta_1 x +e$$

** Parallel regression lines**

another model to consider is one in which dummy variable produces only an additive change in Y

(shifts the regression line up or down )

**regression lines with equal intercepts but different slopes**

*unrelated regression lines**

In unrelated regression lines model, the regression coefficient measure hte additive change in Y due to the dummy variable. the other regression coefficent measures the change in the size of the effect of x on Y dues to the dummy variable. 


## Example: Stylized example: amount spent on travel


```{r}
file<-here('data','travel.txt')
dat<-read.table(file, sep="\t", header=TRUE)

dat$C<-as.factor(dat$C)
```


```{r}
summary(lm.model<-lm(Amount~Age+C+Age:C, data=dat))
```


```{r}
summary(lm.model1<-lm(Amount~Age, data=dat))
```


note that all regression coefficients are highly statistically significant, so we use them all


So for customers in segment A: model predicts

$$Amnt_Spent = 1814.54 - 20.32 x Age$$


while for customers in segment C, the model predicts

$$Amnt_Spent = 6.69+20.13XAge$$



## Comparison of models with anova (analysis of variance)

```{r}
anova(lm.model,lm.model1)
```

if F statistic is high, the models are different


## Menu pricing in Italian restaurant continued


```{r}
file<-here('data','nyc.csv')
dat<-read.csv(file)
```

recall initial model, service had very little effect on price



general consensus on the team that restaurants on east of 5th ave are different than those west. 
```{r}
summary(lm.model1<-lm(Price~Food+Decor+Service+East+ Food:East + Decor:East + Service:East, data=dat))
```

note none of the regression coefficients for the interaction terms are statistically significant.

HOWEVER, both interactions between food:east and Serivce:east  have p=.12



run full model

```{r}
summary(lm.full<-lm(Price~Food+Decor+East, data=dat))
```


Test to see if effect of dummy variable East can be achieved using the following F-test

```{r}
anova(lm.full,lm.model1)
```

since p-value is high, there is little evidence that the predictor values has any effect.





## Exercises


1.

bill collector collecting smal amounts. 

wants to collect delinquent accounts quickly. 

slogan "under 60 days or your money back"


see if amount of money owed is related to the size of the bill

estimate how quickly certain bills will be collected.



DATA:

random sample of accounts over a 6 months. 

variables:

initial size of account

total days to collect in full


first 48 entries are residential

second 48 are commercial

```{r}

file<-here('data','overdue.txt')
dat<-read.table(file, header=TRUE)
#create residential vs commercial factor

dat_res<-dat[1:48,]%>%mutate(TYPE='RESIDENTIAL')
dat_com<-dat[-(1:48),]%>%mutate(TYPE='COMMERCIAL')
dat<-rbind(dat_res, dat_com)
```


```{r}
library(GGally)
ggpairs(dat, mapping=(aes(color=TYPE)))
```


```{r}
summary(lm.full<-lm(LATE~BILL+TYPE, data=dat))
```

```{r}
summary(lm.split<-lm(LATE~BILL+TYPE+TYPE:BILL:., data=dat))
```


## The equations for the linear regression

so when TYPE=0 =commercial...

intercept 101.7 slope =-.19


```{r}
library(stats)

integrand_com<-function(x){-.1909*x+101.7}


```

and when TYPE=1= residential

intercept=101+-99, slope = -.19+.35


```{r}
integrand_res=function(x){(-1.909+.35664)*x+(101-99)}
```

```{r}
ggplot(dat, aes(y=LATE,x=BILL, color=TYPE))+geom_point()
```

I want to analyze mathematically the impact of the 'less than 60 days or your money back' promotion, first piecewise by type and then optimizing for both commercial and residential


### Residential

what we can tell from the residential data, is that people will wait longer to pay if the bill is higher. However from our data set, it does not look like it ever crosses 60 days. 

Strategy:

from our mathematical models, I want to integrate the area under the curve for bills that would be paid under our promotion as 'income' and then subtract reimbursements that the company  would have to pay as 'cost' (cost of running the promotion)


since it looks like we don't buy debts over 311 or below 46, these will be our limits of integration

so our equation will be

PROFIT=income-cost

First we must find the value of the BILL where LATE =60, which will be our upper limit of integration

```{r}
(bill_60<-solve(.166,58))

```



since we dont accept debts above this limit, there will be no cost. You could potentially tell marketing to INCREASE the days that we will give money back guarantees, or even persuade them to increase the limit on debts we will purchase. 


## Commercial:

The commercial sector is a bit more complicated, because businesses WILL wait to pay if the debt is small enough.

First we must find our upper limit for integration

```{r}
(bill_60_commercial<-solve(-.19, (60-101.7)))
```
so income will be debts collected OVER this limit, and cost will be debts uncollected UNDER this limit

```{r}
#profit from commmercial debts

cost_com<-dat%>%filter(TYPE=='COMMERCIAL' & BILL<bill_60_commercial)%>%summarize(sum(BILL))
income_com<-dat%>%filter(TYPE=='COMMERCIAL' & BILL>bill_60_commercial)%>%summarize(sum(BILL))
(profit_com=income_com-cost_com)
```

```{r}
#profits from residential debts

cost_res<-dat%>%filter(TYPE=='RESIDENTIAL' & BILL>bill_60)%>%summarize(sum(BILL))
income_res<-dat%>%filter(TYPE=='RESIDENTIAL' & BILL<bill_60)%>%summarize(sum(BILL))
(profit_res=income_res-cost_res)
```

as we can see this promo will decrease our profits to 42% of what we would have gotten without the promo in place


```{r}
com_profit_pre_promo<-dat%>%filter(TYPE=='COMMERCIAL' )%>%summarize(sum(BILL))
res_profit_pre_promo<-profit_res
profit_promo<-profit_res+profit_com
profit_null<-com_profit_pre_promo+res_profit_pre_promo
percentage_income<-profit_promo/profit_null
```

In order for it to make sense to run this promotion, we need to calculate the increase in business required to break even. 

```{r}
(C=profit_null*1/percentage_income)
```

This is the gross amount required to run the promotion, which is equal to 
```{r}
(C/profit_null)
```

a 234% increase in business. This does not account for a potential effect that our promotion does not change the way customers use our business, causing our regression equations to change. 

```{r}
#residential

```


compare the 2 models

```{r}
anova(lm.full, lm.split)
```

THey are significantly different, so more complex model is selected


```{r}
predict(lm.split, newdata=data.frame(BILL=200, TYPE='COMMERCIAL'), interval='predict')
```



slogan would be good for Residential, because almost all bills under 500 are collected before 60 days, 

for Commercial there should be a minimum, because businesses tend to pay small bills slower

```{r}
#mean and sd of commercial
com_mean<-dat%>%filter(TYPE=='COMMERCIAL')%>%group_by(TYPE)%>%summarise(bill_mean=mean(BILL),late_mean=mean(LATE))
com_sd<-dat%>%filter(TYPE=='COMMERCIAL')%>%group_by(TYPE)%>%summarise(bill_sdn=sd(BILL),late_sd=sd(LATE))


```

```{r}
ls<-c('COMMERCIAL','RESIDENTIAL')
#getting metrics for distributions for creating random data for model
for (i in ls){
  mean<-dat%>%filter(TYPE==i)%>%group_by(TYPE)%>%summarise(bill_mean=mean(BILL),late_mean=mean(LATE))
  
  sd<-dat%>%filter(TYPE==i)%>%group_by(TYPE)%>%summarise(bill_sd=sd(BILL),late_sd=sd(LATE))
  temp<-cbind(mean,sd[-1])
  assign(i, temp)
}
dat_metrics<-rbind(COMMERCIAL,RESIDENTIAL)
```



```{r}
gen_data<-function(dat_metrics=dat_metrics,TYPE='C'){
  if (TYPE=='C'){
    metrics<-dat_metrics%>%filter(TYPE=='COMMERCIAL')%>%select(-TYPE)
    type_select='COMMERCIAL'
  }
  else{
    metrics<-dat_metrics%>%filter(TYPE=='RESIDENTIAL')%>%select(-TYPE)
    type_select='RESIDENTIAL'
  }
  bill_val<-rnorm(mean=metrics$bill_mean,sd=metrics$bill_sd,n=1)
  late_val<-predict(lm.split, newdata=data.frame(BILL=bill_val, TYPE=type_select),interval = 'predict')
  output<-rnorm(mean=late_val[1], sd=(late_val[1]-late_val[2])/2,n=1)
  return(c('bill_val'=bill_val,'late_val'=output))
}
```


```{r}
#generate dataframe of random values for simulation depending on TYPE

gen_frame<-function(gen_func=gen_data, data_metrics=data_metrics, TYPE='C',n=100){
  output_frame=data.frame(bill=double(), late=double())
  for (i in 1:n){
    output_frame=rbind(output_frame, gen_func(data_metrics, TYPE=TYPE))
  }
  names(output_frame)<-c('bill','late')
  return(output_frame)
}
```

```{r}
#commercial frame with real data plotted

df_commercial<-gen_frame(gen_func = gen_data, data_metrics = dat_metrics)
ggplot(df_commercial, aes(x=bill,y=late))+geom_point(color='red')+geom_point(aes(x=BILL,y=LATE), data=dat%>%filter(TYPE=='COMMERCIAL'), color='blue')
```


```{r}
df_residential<-gen_frame(gen_func = gen_data, data_metrics = dat_metrics,TYPE='R')
ggplot(df_residential, aes(x=bill,y=late))+geom_point(color='red')+geom_point(aes(x=BILL,y=LATE), data=dat%>%filter(TYPE=='RESIDENTIAL'), color='blue')
```



```{r}
profit_or_pay<-function(n=1000,TYPE='C', days=60){
  df<-gen_frame(gen_func = gen_data, data_metrics = dat_metrics,TYPE=TYPE)
  df<-df%>%mutate(PROFIT=case_when(
    late>days ~0,
    late<days ~1
  ))
  return(df)
}
```

```{r}
#see if you made money or lost money
pp_sim<-function(TYPE='C', days=d){
  df_out<-data.frame(profit=double())
  for (i in 1:10){
    #print(paste('iter:',i))
    df<-profit_or_pay(n=10, TYPE=TYPE,days=d)
    profit<-df%>%filter(PROFIT==1)%>%summarise(sum(bill))
    loss<-df%>%filter(PROFIT==0)%>%summarise(sum(bill))
    profit<-profit-loss
    df_out<-rbind(df_out,profit)
    
  }
  return(df_out)
}
```

```{r}
df<-profit_or_pay(TYPE='R')
profit<-df%>%filter(PROFIT==1)%>%summarise(sum(bill))
loss<-df%>%filter(PROFIT==0)%>%summarise(sum(bill))
profit-loss
```

```{r}
day_optimizer<-function(d=60){
  print('day optimizer running')
  df<-pp_sim(days=d)
  i=1
  while(round(mean(df$`sum(bill)`),0)!=0){
    df<-pp_sim(days=d)
    print('while loop started')
    print(paste('iter:',i,'days:',d))
    print(mean(df$`sum(bill)`))
  if (mean(df$`sum(bill)`)<0){
    d=d+1
  }else{
    d=d-1
  }
  i=i+1
  }
  print(paste('the optimal number of days is:',d))
}
```



```{r}
library(stats)

integrand<-function(x){1/((x+1)*sqrt(x))}

integrate(integrand, lower=0, upper=Inf)
```


